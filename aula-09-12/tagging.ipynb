{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b996d641-a76e-4efc-90ed-55b1370ad303",
   "metadata": {},
   "source": [
    "# Usando um POS tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febcd4b9-5c9c-4aac-9b93-c710580b8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/ar/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f4a470-e888-454b-bb81-72b6ec73b8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6023d63d-5e34-4695-ab6a-aa94f9a9f181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'NNP'),\n",
       " ('gato', 'NN'),\n",
       " ('branco', 'NN'),\n",
       " ('fugiu', 'NN'),\n",
       " ('do', 'VBP'),\n",
       " ('dono', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# será que existe forma de usar o pos_tag passando idioma? ou seja, existe algum modelo pre-treinado para POR?\n",
    "text = nltk.word_tokenize('O gato branco fugiu do dono.')\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6056d1-2693-4a91-bd9d-8f9bfa15c557",
   "metadata": {},
   "source": [
    "# comentários\n",
    "\n",
    "1. nota sobre POS tags!\n",
    "2. slides\n",
    "3. documentação de UD vs tags MacMorpho (artigo sobre MacMorpho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9ecff-b994-4c4e-8361-980c830751e1",
   "metadata": {},
   "source": [
    "The text.similar() method takes a word w, finds all contexts w1 w w2, then finds all words w' that appear in the same context, i.e. w1 w' w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c152bc1a-83ae-4cff-8797-d607e1eb9270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fad56b6-8657-488b-bc0c-25637bbe0184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in on to of and for with from at by that into as up out down through\n",
      "is all about\n"
     ]
    }
   ],
   "source": [
    "text.similar('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51aeb6a-1300-46f5-92b3-a5d01606d61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a his this their its her an that our any all one these my in your no\n",
      "some other and\n"
     ]
    }
   ],
   "source": [
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b71f76-336f-4e72-96a1-8cea6a526c51",
   "metadata": {},
   "source": [
    "# lendo corpus tageados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c30987-9c57-4f27-9221-91fe1a642f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408d525a-fdd0-4e74-b497-f9e409c18d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.mac_morpho.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017977d0-e9d7-44be-bd65-0a8b1fe7d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# https://stackoverflow.com/questions/29419379/nltk-typeerror-tagged-words-got-an-unexpected-keyword-argument-simplify-ta\n",
    "# como mapeamento é implementado? usa contexto ou apenas 1-1 tags?\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d99bff0-5273-4b7c-b868-47ceb525669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'DET', 'ADJ', 'ADP', '.', 'VERB', 'CONJ', 'NUM', 'ADV', 'PRT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "list(nltk.FreqDist(a[1] for (a,b) in word_tag_pairs if b[1] == 'NOUN'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae6b5df-b1b6-40ba-93ef-8574847cb4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is/VERB',\n",
       " 'said/VERB',\n",
       " 'was/VERB',\n",
       " 'are/VERB',\n",
       " 'be/VERB',\n",
       " 'has/VERB',\n",
       " 'have/VERB',\n",
       " 'will/VERB',\n",
       " 'says/VERB',\n",
       " 'would/VERB',\n",
       " 'were/VERB',\n",
       " 'had/VERB',\n",
       " 'been/VERB',\n",
       " 'could/VERB',\n",
       " \"'s/VERB\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
    "word_tag_fd = nltk.FreqDist(wsj)\n",
    "[word + '/' + tag for (word,tag) in word_tag_fd if tag == 'VERB'][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c145b65-e241-4103-a593-e2249caafbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NOUN', 'VERB'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
    "cfd1['yield'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25e666c-4abe-43ae-a514-d26491d09976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['N', 'V', 'PREP', 'CUR', 'NUM', 'PREP|+', 'ART', 'NPROP', 'PROADJ', ',', 'PRO-KS-REL', 'N|AP', 'ADJ', 'KC', 'VAUX', '(', ')', 'KS', '\"', 'PCP', 'ADV', 'PROPESS', 'V|+', 'PDEN', 'PROSUB', '-', ':', 'PRO-KS', 'VAUX|+', 'ADV-KS-REL', '$', 'N|HOR', ';', 'ART|+', '[', 'ADJ|EST', 'N|EST', 'N|TEL', 'N|DAT', 'KC|[', 'KC|]', '?', '!', 'ADV|[', 'ADV|]', 'ADV-KS', 'ADV|+', 'NUM|TEL', '.', 'IN', \"'\", '/', 'PREP|[', 'PREP|]', 'NPROP|+', 'PREP|', 'NPRO', 'ADV|EST', '...', 'N|DAD', '=', 'VAUX|!', 'ADV|HOR', 'ADJ|+', 'ART|EST', 'PREP|+]', 'PROP', 'V|EST', 'PREP|EST', 'KC|EST', 'PROADJ|+', 'KS|[', 'KS|]', 'IN|EST', 'PROPESS|EST', 'PDEN|EST', '((', '))', '`', 'PROPESS|+', 'KC|+', 'V|!'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import mac_morpho\n",
    "\n",
    "mac_tagged = mac_morpho.tagged_words()\n",
    "mac_fd = nltk.FreqDist(tag for (word, tag) in mac_tagged)\n",
    "mac_fd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8cf9341-6017-4718-99f6-48b3ef0a5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd1 = nltk.ConditionalFreqDist(mac_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a35bf9-17f4-4fe1-94bb-5c6c2832772e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'PCP': 50, 'N': 6, 'KS': 4, 'V': 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1['visto'] # can use .keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c824f6-f066-4f5c-b80d-6f8ba1127e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd2 = nltk.ConditionalFreqDist((tag,word) for (word,tag) in mac_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad817587-1cb6-48d0-ac3c-733d9b040628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'que': 8857, 'se': 877, 'como': 569, 'quando': 549, 'Se': 537, 'porque': 520, 'do': 441, 'Quando': 253, 'Como': 182, 'enquanto': 175, ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2['KS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e672a2cd-bcb5-4dd1-a6b0-35bd049c805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VAUX       V       ,     ADV     ART   NPROP      KC     ADJ PROPESS \n",
      "     30      12       7       4       4       3       1       1       1 \n"
     ]
    }
   ],
   "source": [
    "tags = [a[1] for (a, b) in nltk.bigrams(mac_tagged) if b[0] == 'visto']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b47f2d-d233-4a5b-93dd-58462a9eef0e",
   "metadata": {},
   "source": [
    "# automatic tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327b3f7d-78fb-4792-827b-3dce744f3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e26d8d-6187-4892-a2fe-6536d412e6cb",
   "metadata": {},
   "source": [
    "## default tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b8d0fc-f9ec-494c-bf19-770df5008eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for (word,tag) in brown.tagged_words(categories = 'news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b02c48-a205-4e96-ab96-95631bba1286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "678874ff-c219-4961-9fd2-8c4cae2ddee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/735304995.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  default_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e342d62-7a28-401a-af31-0c177b526c4a",
   "metadata": {},
   "source": [
    "## regex tagger\n",
    "\n",
    "OBS: como poderiamos adaptar para o POR e avaliar com o MacMorpho?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbec64c3-81df-46cc-8323-3b1e42ebe0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    " (r'.*ing$', 'VBG'),               # gerunds\n",
    " (r'.*ed$', 'VBD'),                # simple past\n",
    " (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    " (r'.*ould$', 'MD'),               # modals\n",
    " (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    " (r'.*s$', 'NNS'),                 # plural nouns\n",
    " (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    " (r'.*', 'NN')                     # nouns (default)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a59f9eb2-9dd4-4d85-a982-6da105cb592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', 'NN'),\n",
       " ('Only', 'NN'),\n",
       " ('a', 'NN'),\n",
       " ('relative', 'NN'),\n",
       " ('handful', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('such', 'NN'),\n",
       " ('reports', 'NNS'),\n",
       " ('was', 'NNS'),\n",
       " ('received', 'VBD'),\n",
       " (\"''\", 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('jury', 'NN'),\n",
       " ('said', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('``', 'NN'),\n",
       " ('considering', 'VBG'),\n",
       " ('the', 'NN'),\n",
       " ('widespread', 'NN'),\n",
       " ('interest', 'NN'),\n",
       " ('in', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('election', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('voters', 'NNS'),\n",
       " ('and', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('size', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('this', 'NNS'),\n",
       " ('city', 'NN'),\n",
       " (\"''\", 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(brown_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1126b4a-6dac-4611-9749-10fe0eca3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/108676848.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  regexp_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20326391789486245"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4f9b2-e872-40d8-913d-5d42051d9125",
   "metadata": {},
   "source": [
    "## lookup (UnigramTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "527e31e6-1701-49e2-8b6f-d7e72afe371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/716572578.py:7: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  baseline_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5912942299659885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "most_freq_words = list(fd.keys())[:500] # try 100\n",
    "likely_tags = dict((word, cfd[word].max()) for word in most_freq_words)\n",
    "\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags, backoff = nltk.DefaultTagger('NN')) # remove backoff\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfdca216-47c6-4b39-95a0-a0c6d7ea77e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('DELPH-IN', 'NN'),\n",
       " ('Consortium', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('a', 'AT'),\n",
       " ('collaboration', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('computational', 'NN'),\n",
       " ('linguists', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('research', 'NN'),\n",
       " ('sites', 'NN'),\n",
       " ('world-wide', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = brown.sents(categories='news')[3]\n",
    "sent = nltk.word_tokenize(\"The DELPH-IN Consortium is a collaboration among computational linguists from research sites world-wide.\")\n",
    "baseline_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffa044-a71b-40f1-a26b-1fc6dd5e4f57",
   "metadata": {},
   "source": [
    "### comentários\n",
    "\n",
    "1. avaliação sobre anotação golden\n",
    "2. guidelines (ex participio/adj https://www.conjugacao.com.br/formas-nominais-do-verbo/)\n",
    "3. splitting dev, test and train\n",
    "\n",
    "“Developing an annotated corpus is a major undertaking. Apart from the data, it generates sophisticated tools, documentation, and practices for ensuring high-quality annotation. The tagsets and other coding schemes inevitably depend on some theoretical position that is not shared by all. ”\n",
    "\n",
    "Excerpt From: Steven Bird. “Natural Language Processing with Python.” Apple Books. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474e4d8-26a0-4971-8f20-cd92ef025c89",
   "metadata": {},
   "source": [
    "## N-Gram tagging\n",
    "\n",
    "### UniGram Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2491e43b-df2a-4168-919d-d1f3f7dca03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'QL'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# http://www.nltk.org/api/nltk.tag.html \n",
    "# not using model \n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "334d1990-9496-48c8-912e-857d843e765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/1449911821.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  unigram_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "691d0fb6-fe35-440b-b475-59c490e69c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/3093492045.py:5: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  unigram_tagger.evaluate(test_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51970de4-12d6-40b8-9257-5007c9ffec3f",
   "metadata": {},
   "source": [
    "### general N-Gram tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57168ca4-5c3d-4b04-a8ba-a705451b0149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f12ee73c-d3a4-453b-8306-5634e5cae0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('DELPH-IN', None),\n",
       " ('Consortium', None),\n",
       " ('is', None),\n",
       " ('a', None),\n",
       " ('collaboration', None),\n",
       " ('among', None),\n",
       " ('computational', None),\n",
       " ('linguists', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = nltk.word_tokenize(\"The DELPH-IN Consortium is a collaboration among computational linguists.\")\n",
    "bigram_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3317b93a-a372-463d-b03a-7baf858e53cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/705572540.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  bigram_tagger.evaluate(test_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "717f845f-59ab-45fa-8363-687fb2e9f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/7nbv248s2nq019mcx58xrrb80000gn/T/ipykernel_86939/3878228336.py:4: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  t2.evaluate(test_sents)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8452108043456593"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1) # contexts que apareceram pelo menos X vezes cutoff=2\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0536cb58-ad87-4bcc-a150-947fddaf33be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('DELPH-IN', 'NN'),\n",
       " ('Consortium', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('a', 'AT'),\n",
       " ('collaboration', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('computational', 'NN'),\n",
       " ('linguists', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = nltk.word_tokenize(\"The DELPH-IN Consortium is a collaboration among computational linguists.\")\n",
    "t2.tag(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64e77d-862a-4cb5-ac3b-ceb9f852594a",
   "metadata": {},
   "source": [
    "#### comentários\n",
    "\n",
    "1. tagging unknown words with UNK\n",
    "2. “Thus, 1 out of 20 trigrams is ambiguous. Given the current word and the previous two tags, in 5% of cases there is more than one tag that could be legitimately assigned to the current word according to the training data.” Excerpt From: Steven Bird. “Natural Language Processing with Python.” Apple Books. \n",
    "3. confusion matrix ~> revise tagset\n",
    "4. coarse-grained vs fine-grained tagsets\n",
    "5. como determinar categoria (POS) de uma palavra? \n",
    "6. What kinds of linguistic phenomena are captured in these bigram statistics? \n",
    "7. Para saber mais https://web.stanford.edu/~jurafsky/slp3/3.pdf, nota rodapé pagina 4, ver  https://skeptric.com/ngram-sentence-boundaries/ \n",
    "8. Como implementar? See opensource codes such as Freeling?! Book tem considerações interessantes sobre performance de modelos n-grams.\n",
    "9. Sources from https://www.nltk.org/book/ch05.html (stupid backoff from the slp3 book)\n",
    "10. the HMM is implemented in http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e90ad44c-707f-4f27-b9f2-1a4b76f673b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049297702068029296"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(((x[1], y[1], z[0]), z[1]) \n",
    "                               for sent in brown_tagged_sents \n",
    "                               for x, y, z in nltk.trigrams(sent))\n",
    "ambiguous_contexts = [c for c in cfd.conditions() if len(cfd[c]) > 1]\n",
    "sum(cfd[c].N() for c in ambiguous_contexts) / cfd.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f76a563-288b-44c4-bd29-cfe7723c4add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConfusionMatrix: 52073/61604 correct>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tags = [tag for sent in brown.sents(categories='editorial') \n",
    "             for (word, tag) in t2.tag(sent)]\n",
    "gold_tags = [tag for (word, tag) in brown.tagged_words(categories='editorial')]\n",
    "nltk.ConfusionMatrix(gold_tags, test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf64b7-40bc-4962-a4cf-f0c14ceb11c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
