{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d71a4c-1089-4418-98f3-66a017370a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adc19a-c906-418d-ad69-8d81e4231520",
   "metadata": {},
   "source": [
    "# aulas anteriores\n",
    "\n",
    "Vamos começar com um texto simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2989d2-5cb2-4013-bcc3-8c71e3826c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passo 1: carregando o corpus\n",
    "\n",
    "texto = \"\"\"No meio do caminho tinha uma pedra\n",
    "tinha uma pedra no meio do caminho\n",
    "tinha uma pedra\n",
    "no meio do caminho tinha uma pedra.\"\"\"\n",
    "texto = texto.lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a33d35-a9eb-4dfd-87b2-df18bb14ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra'],\n",
       " ['tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho'],\n",
       " ['tinha', 'uma', 'pedra'],\n",
       " ['no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '.']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passo 2: tokenizando as sentenças\n",
    "\n",
    "texto_tok = [nltk.tokenize.word_tokenize(verso, language='portuguese') for verso in texto]\n",
    "texto_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8763946-38e6-4727-8616-4ae49826f1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra'],\n",
       " ['tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho'],\n",
       " ['tinha', 'uma', 'pedra'],\n",
       " ['no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "tmp = [nltk.tokenize.wordpunct_tokenize(verso) for verso in texto]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c895aa-7565-4163-8043-9520837f3f74",
   "metadata": {},
   "source": [
    "# modelos de linguagem\n",
    "\n",
    "Começamos aqui...\n",
    "\n",
    "1. Veja slides\n",
    "2. https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48bd0746-cfb9-45be-a13e-50592420e60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '</s>'],\n",
       " ['<s>', 'tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho', '</s>'],\n",
       " ['<s>', 'tinha', 'uma', 'pedra', '</s>'],\n",
       " ['<s>', 'no', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', '.', '</s>']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passo 3: inserindo marcadores de início e fim\n",
    "\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "texto_tok_pad = [list(pad_both_ends(v,2)) for v in texto_tok]\n",
    "texto_tok_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a454f4e-55a9-41d7-b831-08afc70e77a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<s>',),\n",
       "  ('<s>', 'no'),\n",
       "  ('no',),\n",
       "  ('no', 'meio'),\n",
       "  ('meio',),\n",
       "  ('meio', 'do'),\n",
       "  ('do',),\n",
       "  ('do', 'caminho'),\n",
       "  ('caminho',),\n",
       "  ('caminho', 'tinha'),\n",
       "  ('tinha',),\n",
       "  ('tinha', 'uma'),\n",
       "  ('uma',),\n",
       "  ('uma', 'pedra'),\n",
       "  ('pedra',),\n",
       "  ('pedra', '</s>'),\n",
       "  ('</s>',)],\n",
       " [('<s>',),\n",
       "  ('<s>', 'tinha'),\n",
       "  ('tinha',),\n",
       "  ('tinha', 'uma'),\n",
       "  ('uma',),\n",
       "  ('uma', 'pedra'),\n",
       "  ('pedra',),\n",
       "  ('pedra', 'no'),\n",
       "  ('no',),\n",
       "  ('no', 'meio'),\n",
       "  ('meio',),\n",
       "  ('meio', 'do'),\n",
       "  ('do',),\n",
       "  ('do', 'caminho'),\n",
       "  ('caminho',),\n",
       "  ('caminho', '</s>'),\n",
       "  ('</s>',)],\n",
       " [('<s>',),\n",
       "  ('<s>', 'tinha'),\n",
       "  ('tinha',),\n",
       "  ('tinha', 'uma'),\n",
       "  ('uma',),\n",
       "  ('uma', 'pedra'),\n",
       "  ('pedra',),\n",
       "  ('pedra', '</s>'),\n",
       "  ('</s>',)],\n",
       " [('<s>',),\n",
       "  ('<s>', 'no'),\n",
       "  ('no',),\n",
       "  ('no', 'meio'),\n",
       "  ('meio',),\n",
       "  ('meio', 'do'),\n",
       "  ('do',),\n",
       "  ('do', 'caminho'),\n",
       "  ('caminho',),\n",
       "  ('caminho', 'tinha'),\n",
       "  ('tinha',),\n",
       "  ('tinha', 'uma'),\n",
       "  ('uma',),\n",
       "  ('uma', 'pedra'),\n",
       "  ('pedra',),\n",
       "  ('pedra', '.'),\n",
       "  ('.',),\n",
       "  ('.', '</s>'),\n",
       "  ('</s>',)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passo 4: calculando n-grams\n",
    "\n",
    "from nltk.util import everygrams\n",
    "ngrams_pad = [list(everygrams(v,max_len=2)) for v in texto_tok_pad]\n",
    "ngrams_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526052c5-989c-4a27-a419-bccaf87a0960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'no',\n",
       " 'meio',\n",
       " 'do',\n",
       " 'caminho',\n",
       " 'tinha',\n",
       " 'uma',\n",
       " 'pedra',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'tinha',\n",
       " 'uma',\n",
       " 'pedra',\n",
       " 'no',\n",
       " 'meio',\n",
       " 'do',\n",
       " 'caminho',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'tinha',\n",
       " 'uma',\n",
       " 'pedra',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'no',\n",
       " 'meio',\n",
       " 'do',\n",
       " 'caminho',\n",
       " 'tinha',\n",
       " 'uma',\n",
       " 'pedra',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passo 5: colocando tokens em lista única\n",
    "\n",
    "from nltk.lm.preprocessing import flatten\n",
    "tokens = list(flatten(texto_tok_pad))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7360358-e59e-4b41-bd36-8c0eca344924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'no',\n",
       " 'meio',\n",
       " 'do',\n",
       " 'caminho',\n",
       " 'tinha',\n",
       " 'uma',\n",
       " 'pedra',\n",
       " '</s>',\n",
       " '.',\n",
       " '<UNK>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passo 6: definindo vocabulário\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "vocab = Vocabulary(tokens, unk_cutoff=1)\n",
    "list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1375e5c6-ebc7-4de1-87aa-8ac790a3a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passo 7: treinando o modelo de linguagem (3,4,5,6)\n",
    "\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "ngrams_pad, vocab = padded_everygram_pipeline(2, texto_tok)\n",
    "lm2 = MLE(2)\n",
    "lm2.fit(ngrams_pad, vocab)\n",
    "\n",
    "ngrams_pad, vocab = padded_everygram_pipeline(1, texto_tok)\n",
    "lm1 = MLE(1)\n",
    "lm1.fit(ngrams_pad, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfb9ea3-49e5-4969-8760-30d0e0ca0ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meio', 'do', 'caminho', 'tinha', 'uma']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.generate(5, text_seed=[\"<s>\",\"no\"]) # comparar com lm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b9eb3c0-394d-419f-801f-5897a7a997aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09090909090909091, -3.4594316186372978)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score('no'), lm2.logscore('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699d1272-2ead-4c8d-ad1e-44ef80e24b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666, -0.5849625007211563)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score('tinha', context = ['caminho']), lm2.logscore('tinha',context = ['caminho'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31825606-97ab-4a82-b1c6-04156e02fd70",
   "metadata": {},
   "source": [
    "# avaliando o modelo\n",
    "\n",
    "1. extrinsic\n",
    "2. intrinsic (perplexity)\n",
    "\n",
    "Para a avaliação intrínseca do ML, precisamos de um conjunto de teste. As probabilidades do ML de n-gram vieram do corpus em que é treinado, o conjunto de treinamento ou corpus de treinamento. Medimos a qualidade do modelo pelo seu desempenho em alguns dados não vistos chamados de conjunto de teste ou corpus de teste.\n",
    "\n",
    "a melhoria de um modelo em perplexidade deve sempre ser confirmada por uma avaliação de ponta a ponta, em uma tarefa real, antes de concluir a avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64bb7377-e6d1-48fa-a33f-dd6c0e5c8f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexidade do unigrama: 7.8712736589589865\n",
      "perplexidade do bigrama: 4.090428596027453\n"
     ]
    }
   ],
   "source": [
    "teste = \"\"\"Tinha uma pedra\n",
    "No meio do caminho\n",
    "Tinha uma pedra.\"\"\"\n",
    "\n",
    "teste = teste.lower().split('\\n')\n",
    "teste_tok = [ nltk.word_tokenize(v, language='portuguese') for v in teste]\n",
    "\n",
    "teste_ng, _ = padded_everygram_pipeline(1, teste_tok)\n",
    "teste_ng = flatten(list(w) for w in teste_ng)\n",
    "\n",
    "# lm to texto\n",
    "p = lm1.perplexity(teste_ng)  \n",
    "print(f\"perplexidade do unigrama: {p}\")\n",
    "\n",
    "teste_ng, _ = padded_everygram_pipeline(2, teste_tok)\n",
    "teste_ng = flatten(list(w) for w in teste_ng)\n",
    "\n",
    "# lm to texto\n",
    "p = lm2.perplexity(teste_ng)\n",
    "print(f\"perplexidade do bigrama: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b3b87-1ab2-441b-ad92-381dbe5d1466",
   "metadata": {},
   "source": [
    "# generalização\n",
    "\n",
    "1. Laplace add-1 smoothing\n",
    "2. Lidstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "555d157d-7cbb-4885-a99c-b3cff883c77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import Laplace\n",
    "\n",
    "ngrams_pad, vocab = padded_everygram_pipeline(2, texto_tok)\n",
    "lm = Laplace(2)\n",
    "lm.fit(ngrams_pad, vocab)\n",
    "lm.score(\"tinha\", context=[\"caminho\"]) # compare com valor anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1332e9bb-f014-4d68-a725-09e2598fcb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5121951219512195"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import Lidstone\n",
    "\n",
    "ngrams_pad, vocab = padded_everygram_pipeline(2, texto_tok)\n",
    "lm = Lidstone(order=2, gamma = 0.1)\n",
    "lm.fit(ngrams_pad, vocab)\n",
    "lm.score(\"tinha\", context=[\"caminho\"]) # compare com valor anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8f1d1-07b4-421e-b7ec-8e63a4dfc52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
